{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksWyf0umtPGH"
      },
      "source": [
        "<img alt=\"Colaboratory logo\" width=\"15%\" src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/novo_logo_bg_claro.png\">\n",
        "\n",
        "#### **Data Science na Prática**\n",
        "*by [sigmoidal.ai](https://sigmoidal.ai)*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co9IDgIytZ1c"
      },
      "source": [
        "# Cross-Validation\n",
        "\n",
        "Como eu comentei na última aula, você não pode assumir que o seu modelo está bom apenas olhando os dados de treino e teste.\n",
        "\n",
        "A filosofia que você deve ter na cabeça é que **o primeiro contato de um modelo de machine learning com dados de teste, deve ocorrer apenas na última etapa do processo.**\n",
        "\n",
        "<center><img src=\"https://images.unsplash.com/photo-1507925921958-8a62f3d1a50d?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1055&q=80\"width=\"70%\"></center>\n",
        "\n",
        "Dentre todos os fatores que nos levam a chegar a essa conclusão, estão os fatos que usar datasets de testes para ajustes, levarão a um provável **overfitting** e carregarão um *bias* (viés).\n",
        "\n",
        "Assim, para que você possa aprender os parâmetros de um modelo e preservar os dados de teste, mostrarei a técnica de **cross-validation**, seguindo o fluxograma da documentação oficial do `sklearn`.\n",
        "\n",
        "<center><img alt=\"Colaboratory logo\" width=\"40%\" src=\"https://raw.githubusercontent.com/carlosfab/dsnp2/master/img/grid_search_workflow.png\"></center>\n",
        "\n",
        "Em tempo, veremos em outra aula como determinar os parâmetros do modelo usando uma técnica conhecida como `grid search`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmQVl6ryvnds"
      },
      "outputs": [],
      "source": [
        "# importar os pacotes necessários\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# garantir replicabilidade\n",
        "np.random.seed(42)\n",
        "\n",
        "# importar o arquivo\n",
        "df = pd.read_csv(\"http://dl.dropboxusercontent.com/s/6d91j46mkcdj4qv/heart-disease-clean.csv?dl=1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOotj1ppwhE8",
        "outputId": "a7c086ea-bf47-4cb0-b719-04d22c9d7c33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scores:  [0.80434783 0.84782609 0.82222222 0.84444444 0.86666667]\n",
            "Acurácia: 0.84 (+/- 0.04)\n"
          ]
        }
      ],
      "source": [
        "# 1. escolher e importar um modelo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# 2. Instanciar e escolher os hyperparameters\n",
        "model = LogisticRegression()\n",
        "\n",
        "# 3. Separar os dados entre feature matrix e target vector\n",
        "X = df.drop('num', axis=1)\n",
        "y = df['num']\n",
        "\n",
        "# 3.1 Dividir o dataset entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# 3.2 Padronizar os dados de treino\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_transformed = scaler.transform(X_train)\n",
        "\n",
        "# 4. Cross-validation\n",
        "scores = cross_val_score(model, X_train_transformed, y_train, cv=5)\n",
        "\n",
        "print(\"scores: \", scores)\n",
        "print(\"Acurácia: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfCPGRCUyxW-"
      },
      "source": [
        "Acima, você pode ver o score médio e o intervalo de confiança de 95%.\n",
        "\n",
        "Por padrão, o score é computado de acordo com o método de score do próprio estimador. No entanto, é possível escolher outra métrica mais alinhada com a realidade do seu dataset.\n",
        "\n",
        "Para conhecer as métricas possíveis, [acesse este link](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q3J2ER0wvU0",
        "outputId": "9231c1b1-9033-402b-951a-fdcefea43270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scores:  [0.79069767 0.82051282 0.78947368 0.78787879 0.85714286]\n"
          ]
        }
      ],
      "source": [
        "scores = cross_val_score(model, X_train_transformed, y_train, cv=5, scoring=\"f1\")\n",
        "print(\"scores: \", scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYmEoRlV055i"
      },
      "source": [
        "Aqui eu quero chamar a atenção para uma coisa. Repare que no primeiro modelo, fizemos a padronização do nosso `X_train_transformed = scaler.transform(X_train)` e somente após usamos a técnica de cross-validation.\n",
        "\n",
        "Vou explicar o motivo dessa não ser uma prática adequada. Veja na imagem abaixo que a cada rodada do nosso k-fold (técnica básica de cross-validation), o subconjunto em azul é deixado como \"teste\".\n",
        "\n",
        "<center><img alt=\"Colaboratory logo\" width=\"40%\" src=\"https://raw.githubusercontent.com/carlosfab/dsnp2/master/img/grid_search_cross_validation.png\"></center>\n",
        "\n",
        "Isso não é ideal, pois queremos simular uma condição onde nosso modelo de machine learning nunca tenha visto esse subconjunto.\n",
        "\n",
        "Essa etapa de padronização ou qualquer outra de pré-processamento, pode ser estruturada com um `pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN445UErytCH",
        "outputId": "2cd7cccf-c844-4650-c215-6e8fc77f7a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scores:  [0.80434783 0.84782609 0.82222222 0.84444444 0.86666667]\n",
            "Acurácia: 0.84 (+/- 0.04)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "\n",
        "print(\"scores: \", scores)\n",
        "print(\"Acurácia: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
