{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Licen√ßa\n",
    "\n",
    "Este Jupyter Notebook foi adaptado a partir do [tutorial oficial da Hopsworks](https://github.com/logicalclocks/hopsworks-tutorials/tree/master/advanced_tutorials/citibike), que est√° sob a [GNU Affero General Public License v3.0 (AGPLv3)](https://www.gnu.org/licenses/agpl-3.0.html). Em conformidade com esta licen√ßa, este trabalho e todas as obras derivadas devem tamb√©m ser compartilhadas sob os mesmos termos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previs√£o de Uso do Citibike\n",
    "\n",
    "<small>01. Feature Backfill</small>\n",
    "\n",
    "<center>\n",
    "<img src='../../assets/m08_projeto_banner.png' alt='Penguins' width=\"600\">\n",
    "</center>\n",
    "\n",
    "üóíÔ∏è O objetivo deste projeto √© demonstrar criar uma solu√ß√£o real de *Machine Learning* para prever o n√∫mero de usu√°rios da Citi Bike em cada esta√ß√£o na cidade de Nova York. Especificamente, voc√™ ir√° criar uma *Feature Store* com o Hopsworks, e fazer o *deploy* de uma aplica√ß√£o com o Streamlit. Este projeto est√° dividido nas seguintes partes:\n",
    "\n",
    "- **Backfill de Features**: Como carregar, engenhar e criar grupos de features.\n",
    "- **Pipeline de Features**: Como analisar novos dados e inseri-los nos grupos de features.\n",
    "- **Pipeline de Treinamento**: Como construir uma visualiza√ß√£o de features, divis√£o do conjunto de dados de treinamento, treinar um modelo e salv√°-lo no Registro de Modelos.\n",
    "- **Pipeline de Infer√™ncia**: Como recuperar um modelo treinado do registro de modelos e us√°-lo para infer√™ncia em lote.\n",
    "- **Implantar um aplicativo Streamlit**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previs√£o de Uso da Citibike\n",
    "\n",
    "Este √© um exemplo avan√ßado do uso do Hopsworks Feature Store, com a tarefa de prever o n√∫mero de usu√°rios da Citibike em cada esta√ß√£o na cidade de Nova York. O Feature Store √© uma parte essencial da infraestrutura de IA que ajuda as organiza√ß√µes a trazer dados empresariais modernos para sistemas de ML anal√≠ticos e operacionais. √â a maneira mais simples e poderosa de levar seus modelos para a produ√ß√£o, de qualquer lugar para qualquer lugar. Voc√™ carregar√° os dados iniciais no feature store, criar√° dois grupos de features a partir dos quais faremos uma visualiza√ß√£o de features e um conjunto de dados de treinamento, e treinar√° um modelo para prever a quantidade de usu√°rios. Al√©m disso, voc√™ projetar√° um pipeline de gera√ß√£o de dados e inser√ß√£o no Feature Store, que ser√° executado periodicamente usando a√ß√µes do GitHub. Um aplicativo Streamlit ser√° criado para que voc√™ possa experimentar seu modelo de maneira interativa.\n",
    "\n",
    "Este √© um caso de uso em lote, que oferecer√° uma vis√£o de alto n√≠vel sobre como usar nossas APIs Python e a interface do usu√°rio para navegar pelos grupos de features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "# Carregar vari√°veis de ambiente\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# Bibliotecas padr√£o\n",
    "from datetime import timedelta, datetime\n",
    "import os\n",
    "\n",
    "# Bibliotecas de an√°lise de dados\n",
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "# Bibliotecas de visualiza√ß√£o\n",
    "import plotly.express as px\n",
    "\n",
    "# M√≥dulos espec√≠ficos do projeto\n",
    "import sigmoidal as sig\n",
    "\n",
    "# Configura√ß√µes gerais\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignorar avisos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOPSWORKS_API_KEY = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "HOPSWORKS_PROJECT_NAME = 'sigmoidal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____ Processando 01/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202301-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "_____ Processando 02/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202302-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "_____ Processando 03/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202303-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "_____ Processando 04/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202304-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "_____ Processando 05/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202305-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "_____ Processando 06/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202306-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "_____ Processando 07/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202307-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "_____ Processando 08/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202308-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "_____ Processando 09/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202309-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "_____ Processando 10/2023... _____\n",
      "https://s3.amazonaws.com/tripdata/202310-citibike-tripdata.csv.zip\n",
      "Recuperando DataFrame do arquivo csv existente...üíø\n",
      "\n",
      "‚úÖ Conclu√≠do ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "df_raw = sig.get_citibike_data(\"01/2023\", \"10/2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>users_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>3633.08</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>3731.11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>3736.03</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>3803.09</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>3834.10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666505</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>8226.06</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666506</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>8226.07</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666507</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>8336.02</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666508</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>8511.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666509</th>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>8582.09</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666510 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  station_id  users_count\n",
       "0       2023-10-01     3633.08           37\n",
       "1       2023-10-01     3731.11           21\n",
       "2       2023-10-01     3736.03           15\n",
       "3       2023-10-01     3803.09           27\n",
       "4       2023-10-01     3834.10           14\n",
       "...            ...         ...          ...\n",
       "666505  2023-01-31     8226.06            8\n",
       "666506  2023-01-31     8226.07            5\n",
       "666507  2023-01-31     8336.02            6\n",
       "666508  2023-01-31     8511.08            1\n",
       "666509  2023-01-31     8582.09            6\n",
       "\n",
       "[666510 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter coluna para string\n",
    "df_raw['station_id'] = df_raw.station_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>users_count</th>\n",
       "      <th>prev_users_count</th>\n",
       "      <th>mean_7_days</th>\n",
       "      <th>mean_14_days</th>\n",
       "      <th>std_7_days</th>\n",
       "      <th>exp_mean_7_days</th>\n",
       "      <th>exp_std_7_days</th>\n",
       "      <th>std_14_days</th>\n",
       "      <th>exp_mean_14_days</th>\n",
       "      <th>exp_std_14_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2932.03</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>6.071429</td>\n",
       "      <td>5.367450</td>\n",
       "      <td>6.506504</td>\n",
       "      <td>5.057768</td>\n",
       "      <td>4.393427</td>\n",
       "      <td>6.286295</td>\n",
       "      <td>4.570934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2951.05</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>12.285714</td>\n",
       "      <td>7.634508</td>\n",
       "      <td>10.978602</td>\n",
       "      <td>6.856891</td>\n",
       "      <td>5.483241</td>\n",
       "      <td>11.905087</td>\n",
       "      <td>6.401791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>3117.05</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.571429</td>\n",
       "      <td>10.214286</td>\n",
       "      <td>4.157609</td>\n",
       "      <td>12.026337</td>\n",
       "      <td>4.462319</td>\n",
       "      <td>4.172779</td>\n",
       "      <td>10.922464</td>\n",
       "      <td>4.265283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>3125.09</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.197505</td>\n",
       "      <td>12.387136</td>\n",
       "      <td>3.553464</td>\n",
       "      <td>4.146361</td>\n",
       "      <td>12.617410</td>\n",
       "      <td>4.165330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>3166.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>2.992053</td>\n",
       "      <td>7.588742</td>\n",
       "      <td>3.088086</td>\n",
       "      <td>2.957575</td>\n",
       "      <td>7.754732</td>\n",
       "      <td>3.401655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date station_id  users_count  prev_users_count  mean_7_days  \\\n",
       "0  2023-01-02    2932.03           12               3.0     7.142857   \n",
       "1  2023-01-02    2951.05            4               2.0    12.571429   \n",
       "2  2023-01-02    3117.05            4              10.0    11.571429   \n",
       "3  2023-01-02    3125.09           10              11.0    13.571429   \n",
       "4  2023-01-02    3166.03            6               3.0     7.428571   \n",
       "\n",
       "   mean_14_days  std_7_days  exp_mean_7_days  exp_std_7_days  std_14_days  \\\n",
       "0      6.071429    5.367450         6.506504        5.057768     4.393427   \n",
       "1     12.285714    7.634508        10.978602        6.856891     5.483241   \n",
       "2     10.214286    4.157609        12.026337        4.462319     4.172779   \n",
       "3     12.500000    4.197505        12.387136        3.553464     4.146361   \n",
       "4      7.142857    2.992053         7.588742        3.088086     2.957575   \n",
       "\n",
       "   exp_mean_14_days  exp_std_14_days  \n",
       "0          6.286295         4.570934  \n",
       "1         11.905087         6.401791  \n",
       "2         10.922464         4.265283  \n",
       "3         12.617410         4.165330  \n",
       "4          7.754732         3.401655  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# existem linhas duplicadas (v√°rios registros para o mesmo dia e esta√ß√£o). vamos remov√™-las.\n",
    "df_res = df_raw.copy()\n",
    "df_res = df_res.groupby(['date', 'station_id'], as_index=False)['users_count'].sum()\n",
    "\n",
    "df_res['prev_users_count'] = df_res.groupby('station_id')[\n",
    "    'users_count'\n",
    "].shift(+1)\n",
    "df_res = df_res.dropna()\n",
    "df_res = sig.moving_average(df_res, 7)\n",
    "df_res = sig.moving_average(df_res, 14)\n",
    "\n",
    "for i in [7, 14]:\n",
    "    for func in [\n",
    "        sig.moving_std,\n",
    "        sig.exponential_moving_average,\n",
    "        sig.exponential_moving_std,\n",
    "    ]:\n",
    "        df_res = func(df_res, i)\n",
    "df_res = df_res.reset_index(drop=True)\n",
    "df_res = df_res.sort_values(by=['date', 'station_id']).dropna()\n",
    "\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any null values\n",
    "df_res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the dataset\n",
    "df_res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random station, using method sample, and filter the dataset\n",
    "station_id = df_res.station_id.sample().values[0]\n",
    "df_res[df_res.station_id == station_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
